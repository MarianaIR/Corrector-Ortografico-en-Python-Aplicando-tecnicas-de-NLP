# âœï¸ CORRECTOR ORTOGRÃFICO EN PYTHON: APLICANDO TÃ‰CNICAS DE NLP

[![Python](https://img.shields.io/badge/Python-3670A0?style=flat&logo=python&logoColor=ffdd54)](https://www.python.org/)Â Â 
[![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white)](https://numpy.org/)Â Â 
[![NLTK](https://img.shields.io/badge/NLTK-283990?style=flat&logo=python&logoColor=white)](https://www.nltk.org/)

Este proyecto simula la **creaciÃ³n de un corrector ortogrÃ¡fico** utilizando **Procesamiento de Lenguaje Natural (NLP)** y lÃ³gica computacional en Python. El objetivo es construir un "traductor/transmisor" que sea capaz de interpretar una palabra mal escrita por un humano y devolver la palabra correctamente escrita.

---

## ğŸ§  Contenido del Proyecto

### 1ï¸âƒ£ Fundamentos de NLP
- **DefiniciÃ³n de NLP:** Se establece que NLP es la ciencia que combina **LingÃ¼Ã­stica + ComputaciÃ³n + Inteligencia Artificial** para simular un traductor, permitiendo que las mÃ¡quinas interpreten el lenguaje humano natural.
- **Caso de Uso:** La simulaciÃ³n se basa en mejorar la funcionalidad de un buscador (ej. una plataforma que no corrige errores ortogrÃ¡ficos) para que pueda sugerir la palabra correcta aun cuando el usuario la escriba mal.

### 2ï¸âƒ£ MetodologÃ­a de CorrecciÃ³n
- **Manejo de Vocabulario:** El modelo se entrena en un **corpus de texto** para generar un diccionario de palabras conocidas y sus frecuencias.
- **Distancia de EdiciÃ³n (Inferido):** El proceso implica generar posibles correcciones para una palabra errÃ³nea y medir quÃ© tan cerca estÃ¡ cada correcciÃ³n de una palabra conocida del diccionario.
- **CÃ¡lculo de Frecuencia:** La correcciÃ³n final se selecciona no solo por la cercanÃ­a, sino tambiÃ©n por la **frecuencia de uso** de la palabra en el lenguaje.

### 3ï¸âƒ£ EvaluaciÃ³n y Mejora del Modelo
- **MÃ©trica de Acertividad:** Se calcula la *accuracity* (acertividad) del modelo midiendo cuÃ¡ntas de sus correcciones coinciden con la correcciÃ³n real esperada.
- **AnÃ¡lisis de Capacidad MÃ¡xima:** Se determina la **mÃ¡xima acertividad posible (88%)** con los datos actuales.
- **IdentificaciÃ³n de Brechas:** Se cuantifica el porcentaje de mejora potencial (**aproximadamente 22.9%**), destacando que se pueden incluir mÃ¡s escenarios para optimizar el modelo (ej. considerar palabras con mÃºltiples errores como LÃ“GGGICA).

---

## ğŸ› ï¸ LibrerÃ­as Utilizadas

| LibrerÃ­aÂ  Â  Â  Â | Uso principalÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â |
|----------------|---------------------------------------------|
| **Python**Â  Â  Â | Lenguaje base para la implementaciÃ³n de la lÃ³gica del corrector|
| **NumPy**Â  Â  Â  | Operaciones numÃ©ricas para la manipulaciÃ³n y conteo de datos (inferido) |
| **NLTK (Natural Language Toolkit)** | (Uso fundamental inferido) LibrerÃ­a para el preprocesamiento de texto, tokenizaciÃ³n y manejo del vocabulario |

---

## ğŸ¯ Objetivo del Proyecto
Crear un **corrector ortogrÃ¡fico funcional** que demuestre los principios bÃ¡sicos de NLP. El proyecto busca mostrar cÃ³mo se pueden aplicar la lingÃ¼Ã­stica y la probabilidad para interpretar el lenguaje natural y **mejorar la experiencia del usuario** en sistemas de bÃºsqueda y entrada de texto.

---

## ğŸ“ˆ Resultados Clave
- El modelo inicial logra una **acertividad de aproximadamente 65.71%**.
- Se establece una meta de mejora teÃ³rica de hasta **88%** al incluir mÃ¡s escenarios de error y mejorar la lÃ³gica de correcciÃ³n.
- La principal conclusiÃ³n es la necesidad de **seguir incluyendo escenarios** (como errores con 3 letras repetidas) para alcanzar el potencial mÃ¡ximo de correcciÃ³n del modelo.

